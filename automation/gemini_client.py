# -*- coding: utf-8 -*-
import os
import base64
import json
from google import genai
from google.genai import types
from dotenv import load_dotenv
import time
import random
import textwrap


load_dotenv(override=True)

class GeminiClient:
    def __init__(self):
        self.project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
        self.location = os.getenv("GOOGLE_CLOUD_LOCATION")
        self.api_key = os.getenv("GEMINI_API_KEY")
        self.client = None
        self.use_vertex = False

        # Prioritize Vertex AI initialization
        if self.project_id and self.location:
            try:
                print(f"Initializing Gemini with Vertex AI (Project: {self.project_id}, Location: {self.location})")
                self.client = genai.Client(vertexai=True, project=self.project_id, location=self.location)
                self.use_vertex = True
            except Exception as e:
                print(f"Warning: Vertex AI initialization failed: {e}, falling back to API Key.")
                self.use_vertex = False
        
        # Fallback to API Key if Vertex AI is not available
        if not self.use_vertex:
            if self.api_key:
                print("Initializing Gemini with API Key (google-genai)")
                self.client = genai.Client(api_key=self.api_key)
            else:
                raise ValueError("Missing Gemini credentials. Set GOOGLE_CLOUD_PROJECT/LOCATION or GEMINI_API_KEY in .env")

    def _retry_request(self, func, *args, **kwargs):
        """
        Retry a function call with exponential backoff if a quota error occurs.
        """
        max_retries = 5
        base_delay = 2  # seconds
        
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                error_str = str(e).lower()
                # Check for rate limit/quota errors
                if "429" in error_str or "quota" in error_str or "exhausted" in error_str:
                    if attempt == max_retries - 1:
                        print(f"Max retries ({max_retries}) exceeded for quota error.")
                        raise e
                    
                    delay = (base_delay * (2 ** attempt)) + (random.random() * 1)
                    print(f"Quota exceeded (429). Retrying in {delay:.2f}s... (Attempt {attempt + 1}/{max_retries})")
                    time.sleep(delay)
                else:
                    # Not a quota error, raise immediately
                    raise e

    def generate_content(self, prompt, model='gemini-3-pro-preview', config=None):
        """
        Generic method to generate content with retry logic.
        """
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model=model,
                contents=prompt,
                config=config
            )
            return response
        except Exception as e:
            print(f"Error generating content: {e}")
            return None

    def generate_article(self, keyword, article_type="topic-focus", context=None, extra_instructions=None, category=None):
        """
        Generate a full blog article in Markdown format.
        
        Args:
            keyword: Main topic or title.
            article_type: "topic-focus" (Deep Dive) is the primary type.
        """
        print(f"Generating article for keyword: {keyword} (Type: {article_type}, Category: {category})")
        
        # Normalize type: 'featured-news' -> 'topic-focus'
        if article_type == 'featured-news':
            article_type = 'topic-focus'
            
        context_section = ""
        if context:
            context_section = f"""
            ## Context Information
            The following external information is relevant to the topic. Use it to ensure accuracy and freshness.
            Summary: {context.get('summary', '')}
            Key Facts: {', '.join(context.get('key_facts', []))}
            Analyst View: {context.get('finshift_view', '')}
            """
            
        prompts = {
            # --- TechShift Primary Prompt ---
            # [Topic Deep Dive] Single article focus.
            "topic-focus": textwrap.dedent(f"""
            {context_section}ã‚ãªãŸã¯å°‚é–€æŠ€è¡“ã‚¢ãƒŠãƒªã‚¹ãƒˆï¼ˆTech Analystï¼‰ã§ã™ã€‚
            ç‰¹å®šã®æŠ€è¡“ãƒˆãƒ”ãƒƒã‚¯ï¼ˆ{keyword}ï¼‰ã«ã¤ã„ã¦ã€ãã®æŠ€è¡“ã®å½±éŸ¿ã‚’æ·±æ˜ã‚Šã™ã‚‹è§£èª¬è¨˜äº‹ã‚’åŸ·ç­†ã—ã¦ãã ã•ã„ã€‚
            
            ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}
            
            ## ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            - ãã®æŠ€è¡“ã®å®Ÿç”¨åŒ–æ™‚æœŸã‚’çœŸå‰£ã«è¿½ã£ã¦ã„ã‚‹ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã‚„æŠ•è³‡å®¶
            
            ## åŸ·ç­†ãƒ­ã‚¸ãƒƒã‚¯ (Level 2 Granularity)
            - å˜ã«ã€Œå®Ÿç”¨åŒ–ã€ã ã‘ã§ãªãã€ã€ŒæŠ€è¡“çš„çµ¶å¯¾æ¡ä»¶ (Prerequisites)ã€ã®é”æˆåº¦ã«ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ã™ã‚‹ã€‚
            - ä¾‹: "å…¨å›ºä½“é›»æ± ã®å®Ÿç”¨åŒ–" ã§ã¯ãªã "é›»è§£è³ªä¼å°ç‡ 10mS/cm ã®é”æˆ" ã«æ³¨ç›®ã€‚
            
            ## æ§‹æˆæ¡ˆ (TechShift Standard)
            
            1. **ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆè¦ç´„ (The Shift)**:
               - å˜ãªã‚‹ãƒ‹ãƒ¥ãƒ¼ã‚¹ã®è¦ç´„ã§ã¯ãªãã€ã€Œã“ã®æŠ€è¡“ç™»å ´ã®å‰å¾Œã§ã€ä¸–ç•Œï¼ˆãƒ«ãƒ¼ãƒ«ï¼‰ãŒã©ã†å¤‰ã‚ã£ãŸã‹ã€ã‚’å¯¾æ¯”ã•ã›ã‚‹ã€‚
               - Format: ã€Œã“ã‚Œã¾ã§ã¯XãŒé™ç•Œã ã£ãŸãŒã€Yã«ã‚ˆã£ã¦ZãŒå¯èƒ½ã«ãªã£ãŸã€
            
            2. **æŠ€è¡“çš„ç‰¹ç•°ç‚¹ (Technical Catalyst)**:
               - ãªãœãã‚ŒãŒå¯èƒ½ã«ãªã£ãŸã®ã‹ï¼Ÿï¼ˆWhy Now?ï¼‰
               - æ—¢å­˜æŠ€è¡“(SOTA)ã¨ã®æ±ºå®šçš„ãªé•ã„ï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€ç´ æã€æ‰‹æ³•ï¼‰ã‚’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢è¦–ç‚¹ã§è§£èª¬ã€‚
            
            3. **æ¬¡ãªã‚‹èª²é¡Œ (The Next Wall)**:
               - ä¸€ã¤ã®èª²é¡ŒãŒè§£æ±ºã•ã‚Œã‚‹ã¨ã€å¿…ãšæ–°ã—ã„ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ãŒå‡ºç¾ã™ã‚‹ã€‚
               - ã€Œç²¾åº¦ã¯è§£æ±ºã—ãŸãŒã€æ¨è«–ã‚³ã‚¹ãƒˆãŒèª²é¡Œã€ã€Œå®Ÿé¨“å®¤ã§ã¯æˆåŠŸã—ãŸãŒã€é‡ç”£ãƒ—ãƒ­ã‚»ã‚¹ãŒæœªç¢ºç«‹ã€ãªã©ã€æ¬¡ã«ç›´é¢ã™ã‚‹ãƒªã‚¢ãƒªãƒ†ã‚£ã®ã‚ã‚‹èª²é¡Œã‚’æŒ‡æ‘˜ã™ã‚‹ã€‚
            
            4. **ä»Šå¾Œã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆ (Strategic Signal)**:
               - æŠ•è³‡å®¶ã‚„ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãŒã€æ¥é€±ãƒ»æ¥æœˆãƒ»æ¥å¹´ãƒã‚§ãƒƒã‚¯ã™ã¹ãå…·ä½“çš„ãªæŒ‡æ¨™ï¼ˆKPIï¼‰ã€‚
               - æŠ½è±¡çš„ãªã€ŒæœŸå¾…ã€ã§ã¯ãªãã€ã€Œã©ã®æ•°å€¤ãŒæ”¹å–„ã•ã‚ŒãŸã‚‰GOã‚µã‚¤ãƒ³ã‹ã€ã‚’æç¤ºã€‚

            5. **çµè«– (Verdict)**:
               - çµå±€ã€ã“ã®æŠ€è¡“ã¯ã€Œè²·ã„ã€ãªã®ã‹ã€Œå¾…ã¡ã€ãªã®ã‹ã€ã‚ã‚‹ã„ã¯ã€Œä½•å¾…ã¡ã€ãªã®ã‹ã€‚
               - èª­è€…ãŒå–ã‚‹ã¹ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¤ºå”†ã—ã¦ç· ã‚ããã‚‹ã€‚
            
            ## åŸ·ç­†ãƒˆãƒ¼ãƒ³
            - **Insightful**: äº‹å®Ÿã®ç¾…åˆ—ã§ã¯ãªãã€ç‚¹ã¨ç‚¹ã‚’ç·šã§çµã¶è§£é‡ˆã‚’åŠ ãˆã‚‹ã€‚
            - **Professional**: ç…½ã‚Šæ–‡å¥ã¯ä¸è¦ã€‚å†·å¾¹ãªåˆ†æã¨ç†±é‡ã®ã‚ã‚‹ãƒ“ã‚¸ãƒ§ãƒ³ã‚’ä¸¡ç«‹ã•ã›ã‚‹ã€‚
               
            
            ## åŸ·ç­†ãƒ«ãƒ¼ãƒ«
            - **ä¸€æ¬¡æƒ…å ±ä¸»ç¾©**: è«–æ–‡ã‚„å…¬å¼ãƒªãƒªãƒ¼ã‚¹ã«åŸºã¥ãäº‹å®Ÿã®ã¿ã‚’æ‰±ã†ã€‚å™‚ãƒ¬ãƒ™ãƒ«ã¯é™¤å¤–ã€‚
            - **å†·é™ãªè©•ä¾¡**: "é©å‘½çš„" "ç ´å£Šçš„" ã¨ã„ã£ãŸå½¢å®¹è©ã‚’é¿ã‘ã€æ•°å€¤ã§èªã‚‹ã€‚
            
            ## ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            - Markdownå½¢å¼
            - 4000æ–‡å­—ç¨‹åº¦
            - æŠ€è¡“ä»•æ§˜ã¯ãƒ†ãƒ¼ãƒ–ãƒ«ã§æ¯”è¼ƒ
            - HTMLã‚¿ã‚°ä½¿ç”¨ç¦æ­¢
            
            ## ã‚¿ã‚¤ãƒˆãƒ«ä½œæˆãƒ«ãƒ¼ãƒ« (SEO Optimized)
            - **ç›®çš„**: æ¤œç´¢æµå…¥ã®æœ€å¤§åŒ– (High CTR & Search Volume)ã€‚
            - **ãƒ«ãƒ¼ãƒ«1 (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é…ç½®)**: æ¤œç´¢ã•ã‚Œã‚„ã™ã„ã€Œãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€ã‚’å¿…ãš**æ–‡é ­**ã«ç½®ãã€‚
            - **ãƒ«ãƒ¼ãƒ«2 (ã‚µã‚¸ã‚§ã‚¹ãƒˆæ„è­˜)**: ã€Œä»•çµ„ã¿ã€ã€Œã„ã¤ã€ã€Œèª²é¡Œã€ã€Œãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã€ã€Œå°†æ¥æ€§ã€ãªã©ã€ã‚ˆãæ¤œç´¢ã•ã‚Œã‚‹ã‚µã‚¸ã‚§ã‚¹ãƒˆãƒ¯ãƒ¼ãƒ‰ã‚’å«ã‚ã‚‹ã€‚
            - **å½¢å¼**: [ãƒ¡ã‚¤ãƒ³ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰]ï¼‹[æ¤œç´¢æ„å›³ã‚’æº€ãŸã™å…·ä½“çš„ãªå†…å®¹]
            - **æ‚ªã„ä¾‹**: ã€Œä»Šå›ã®ãƒ–ãƒ¬ã‚¤ã‚¯ã‚¹ãƒ«ãƒ¼ã«ã‚ˆã‚Šå…¨å›ºä½“é›»æ± ãŒé€²åŒ–ã€ (ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå¾Œã‚)
            - **è‰¯ã„ä¾‹**: 
              - ã€Œå…¨å›ºä½“é›»æ± ã®é‡ç”£ã¯ã„ã¤ï¼Ÿæœ€æ–°ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¨2ã¤ã®æŠ€è¡“çš„èª²é¡Œã€
              - ã€ŒAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ä»•çµ„ã¿ã¨ã¯ï¼Ÿè‡ªå¾‹å‹•ä½œã®åŸç†ã¨3ã¤ã®å®Ÿç”¨ä¾‹ã€
              - ã€Œæ ¸èåˆç™ºé›»ã®ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’å¾¹åº•è§£èª¬ï½œ2030å¹´ã®å®Ÿç”¨åŒ–äºˆæ¸¬ã€
            """)
        }
        
        # Select prompt
        prompt = prompts.get(article_type, prompts["topic-focus"])
        
        if extra_instructions:
            prompt += f"\n\n{extra_instructions}\n"
        
        # Add common formatting instruction
        prompt += textwrap.dedent("""
        
        ## å‡ºåŠ›å½¢å¼
        å¿…ãšä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š
        
        1è¡Œç›®: # [ç”Ÿæˆã—ãŸã‚¿ã‚¤ãƒˆãƒ«]
        2è¡Œç›®: ç©ºè¡Œ
        3è¡Œç›®ä»¥é™: è¨˜äº‹æœ¬æ–‡ï¼ˆå°å…¥ã‹ã‚‰å§‹ã‚ã‚‹ï¼‰
        
        **è¦‹å‡ºã—ãƒ¬ãƒ™ãƒ«:**
        - ã‚¿ã‚¤ãƒˆãƒ«: # (H1) â† è¨˜äº‹ã®ä¸»é¡Œ
        - å¤§è¦‹å‡ºã—: ## (H2) â† è¨˜äº‹ã®ä¸»è¦ãªæ§‹æˆè¦ç´ ï¼ˆç« ï¼‰
        - ä¸­è¦‹å‡ºã—: ### (H3) â† ç« ã‚’æ§‹æˆã™ã‚‹å…·ä½“çš„ãªãƒˆãƒ”ãƒƒã‚¯ï¼ˆç¯€ï¼‰
        
        **ã€é‡è¦ã€‘Markdownè¨˜è¿°ãƒ«ãƒ¼ãƒ«:**
        - **ãƒªã‚¹ãƒˆï¼ˆç®‡æ¡æ›¸ãï¼‰ã®å‰ã«ã¯å¿…ãšç©ºè¡Œã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚**
        - **ãƒã‚¹ãƒˆï¼ˆå…¥ã‚Œå­ï¼‰ã—ãŸãƒªã‚¹ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã¯å¿…ãšåŠè§’ã‚¹ãƒšãƒ¼ã‚¹4ã¤ï¼ˆ4 spacesï¼‰ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚**
        
        ä¾‹:
        # ã€æŠ€è¡“è§£èª¬ã€‘æ¬¡ä¸–ä»£åŠå°ä½“ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒ³ã‚°æŠ€è¡“ã®çªç ´å£
        
        ## 1. Executive Summary
        MITã®ç ”ç©¶ãƒãƒ¼ãƒ ãŒç™ºè¡¨ã—ãŸæ–°ã—ã„...
        
        ## 2. Technical Spec
        | é …ç›® | ä»Šå›ã®æˆæœ | å¾“æ¥æŠ€è¡“ |
        | :--- | :--- | :--- |
        | é…ç·šå¯†åº¦ | ... | ... |
        """)
        
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model='gemini-3-pro-preview',
                contents=prompt
            )
            return response.text
        except Exception as e:
            print(f"Error generating content: {e}")
            return None

    def generate_image(self, prompt, output_path, aspect_ratio="16:9"):
        """
        Generate an image using Gemini 2.5 Flash Image (Primary) or Imagen 3.0 (Fallback).
        """
        # 1. Try Gemini 2.5 Flash Image (API Key supported)
        try:
            print(f"Generating image with Gemini 2.5 Flash Image for prompt: {prompt}")
            
            # Use google-genai SDK (v1beta) for API Key support and aspect ratio control
            client_v1beta = genai.Client(api_key=self.api_key, vertexai=False, http_options={'api_version': 'v1beta'})
            
            response = client_v1beta.models.generate_content(
                model='gemini-2.5-flash-image',
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_modalities=["IMAGE"],
                    image_config=types.ImageConfig(
                        aspect_ratio=aspect_ratio,
                    )
                )
            )
            
            # Extract image from response (Gemini 2.5 Flash)
            if response.parts:
                for part in response.parts:
                    if part.inline_data is not None:
                        image_bytes = part.inline_data.data
                        with open(output_path, 'wb') as f:
                            f.write(image_bytes)
                        print(f"Image saved to: {output_path}")
                        return output_path
            
            print("No image found in Gemini 2.5 response, trying fallback...")
            
        except Exception as e:
            print(f"Gemini 2.5 Flash Image failed ({e}), falling back to Imagen 3.0...")

        # 2. Fallback to Imagen 3.0 (Vertex AI only)
        try:
            print(f"Generating image with Imagen 3.0 (Fallback) for prompt: {prompt}")
            
            response = self._retry_request(
                self.client.models.generate_images,
                model='imagen-3.0-generate-001',
                prompt=prompt,
                config={
                    'aspect_ratio': aspect_ratio
                }
            )
            
            # Extract image from response (Imagen 3.0)
            if response.generated_images:
                image_bytes = response.generated_images[0].image.image_bytes
                with open(output_path, 'wb') as f:
                    f.write(image_bytes)
                print(f"Image saved to: {output_path}")
                return output_path
            
            print("No image generated in Imagen 3.0 response.")
            return None
                
        except Exception as e:
            print(f"Failed to generate image with Imagen 3.0: {e}")
            return None


    def generate_image_prompt(self, title, content_summary, article_type="topic-focus"):
        """
        Generate an optimized English image prompt based on article title and content.
        
        Args:
            title: Article title
            content_summary: Brief summary
            article_type: Type of article (topic-focus, daily-briefing)
        
        Returns:
            English image prompt optimized for Imagen 3.0/Gemini 2.5
        """
        prompt = textwrap.dedent(f"""
        You are an expert at creating image generation prompts for Imagen 3.0.
        
        Based on the following article information, create a detailed English image prompt that:
    1. **Theme**: "Future Technology", "Innovation", "Cyberpunk/High-Tech Sci-Fi".
    2. **Visual Metaphors**: 
       - **Futuristic**: Neon lights, data streams, holograms, advanced robotics, space exploration.
       - **Abstract**: Geometric patterns, circuit boards, glowing nodes connecting (representing networks).
    3. **Style**: Premium, Editorial, "Wired Magazine" or "The Verge" feature image style. High contrast, vibrant colors (Cyan, Magenta, Deep Blue).
    4. **Lighting**: Cinematic, Volumetric lighting, Ray tracing vibes.
    5. Avoids text, human faces, or complex diagrams.
    
    Article Title: {title}
    Article Type: {article_type}
    Content Summary: {content_summary[:2000]}
    
    Generate a single, detailed English image prompt (max 100 words) that would create a compelling hero image for this article.
    Output ONLY the prompt text, no explanations.
        """)
        
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model='gemini-3-pro-preview',
                contents=prompt
            )
            return response.text.strip()
        except Exception as e:
            print(f"Error generating image prompt: {e}")
            # Fallback to simple prompt
            return f"Futuristic technology background related to {title}, cyberpunk style, high quality, 4k"



    def generate_static_page(self, page_type):
        """
        Generate static page content (privacy policy, about, contact).
        
        Args:
            page_type: "privacy", "about", or "contact"
        
        Returns:
            Generated markdown content
        """
        prompts = {
            "privacy": textwrap.dedent("""
            ã‚ãªãŸã¯æ³•å‹™ã«è©³ã—ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚
            ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€æ—¥æœ¬ã®å€‹äººæƒ…å ±ä¿è­·æ³•ã«æº–æ‹ ã—ãŸãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            
            ã€ã‚µã‚¤ãƒˆæƒ…å ±ã€‘
            - ã‚µã‚¤ãƒˆå: TechShiftï¼ˆãƒ†ãƒƒã‚¯ã‚·ãƒ•ãƒˆï¼‰
            - é‹å–¶è€…: TechShiftç·¨é›†éƒ¨
            - è¨­ç«‹: 2026å¹´1æœˆ
            - ç›®çš„: æŠ€è¡“ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®å¯è¦–åŒ–ãƒ»äºˆæ¸¬æƒ…å ±ã®æä¾›
            - ä½¿ç”¨æŠ€è¡“: Googleã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ã€Cookie
            - ãŠå•ã„åˆã‚ã›: info@finshift.net
            
            ## å«ã‚ã‚‹ã¹ãé …ç›®
            1. å€‹äººæƒ…å ±ã®å–ã‚Šæ‰±ã„ã«ã¤ã„ã¦
            2. åé›†ã™ã‚‹æƒ…å ±ã®ç¨®é¡ï¼ˆã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°ã€Cookieç­‰ï¼‰
            3. åˆ©ç”¨ç›®çš„ï¼ˆã‚µã‚¤ãƒˆæ”¹å–„ã€çµ±è¨ˆåˆ†æç­‰ï¼‰
            4. ç¬¬ä¸‰è€…æä¾›ï¼ˆGoogleã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹ç­‰ï¼‰
            5. Cookieãƒ»ã‚¢ã‚¯ã‚»ã‚¹è§£æãƒ„ãƒ¼ãƒ«ã«ã¤ã„ã¦
            6. å…è²¬äº‹é …ï¼ˆæœ¬ã‚µã‚¤ãƒˆã®æƒ…å ±ã¯äºˆæ¸¬ã§ã‚ã‚Šã€æ­£ç¢ºæ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ãªã„æ—¨ï¼‰
            7. å€‹äººæƒ…å ±ã®é–‹ç¤ºãƒ»è¨‚æ­£ãƒ»å‰Šé™¤ã«ã¤ã„ã¦
            8. ãŠå•ã„åˆã‚ã›å…ˆ
            9. åˆ¶å®šæ—¥ãƒ»æ”¹å®šæ—¥
            
            ## å‡ºåŠ›å½¢å¼
            - Markdownå½¢å¼ã§å‡ºåŠ›
            - è¦‹å‡ºã—ã¯H2ï¼ˆ##ï¼‰ã¨H3ï¼ˆ###ï¼‰ã‚’ä½¿ç”¨
            - ç®‡æ¡æ›¸ãã‚„è¡¨ã‚’é©å®œä½¿ç”¨
            - æ³•çš„ã«æ­£ç¢ºã§ã€ã‹ã¤èª­ã¿ã‚„ã™ã„æ–‡ç« 
            - æœ€å¾Œã«ã€Œåˆ¶å®šæ—¥: 2026å¹´1æœˆ1æ—¥ã€ã‚’è¨˜è¼‰
            
            ## æ³¨æ„ç‚¹
            - å°‚é–€ç”¨èªã¯åˆ†ã‹ã‚Šã‚„ã™ãèª¬æ˜
            - **æŠ€è¡“äºˆæ¸¬ãƒ»æŠ•è³‡åˆ¤æ–­ã¯è‡ªå·±è²¬ä»»**ã§ã‚ã‚‹ã¨ã„ã†å…è²¬ã‚’å¿…ãšå«ã‚ã‚‹
            - é€£çµ¡å…ˆã‚’æ˜è¨˜
            """),
            
            "about": textwrap.dedent("""
            ã‚ãªãŸã¯ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ãƒˆã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å°‚é–€å®¶ã§ã™ã€‚
            ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€TechShiftã®é‹å–¶è€…æƒ…å ±ãƒšãƒ¼ã‚¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            
            ã€ã‚µã‚¤ãƒˆæƒ…å ±ã€‘
            - ã‚µã‚¤ãƒˆå: TechShiftï¼ˆãƒ†ãƒƒã‚¯ã‚·ãƒ•ãƒˆï¼‰
            - é‹å–¶è€…: TechShiftç·¨é›†éƒ¨
            - è¨­ç«‹: 2026å¹´1æœˆ
            - ãŠå•ã„åˆã‚ã›: info@finshift.net
            
            ã€ãƒ“ã‚¸ãƒ§ãƒ³: "Dynamic Navigation Chart"ã€‘
            æ—¢å­˜ã®é™çš„ãªãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ï¼ˆPDFï¼‰ã‚’éå»ã®ã‚‚ã®ã¨ã—ã€
            æ—¥ã€…ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è§£æã‚’é€šã˜ã¦ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§æ›´æ–°ã•ã‚Œç¶šã‘ã‚‹ã€Œå‹•çš„èˆªæµ·å›³ã€ã‚’æä¾›ã™ã‚‹ã€‚
            
            ã€ã‚¿ãƒ¼ã‚²ãƒƒãƒˆèª­è€…: "Visionary Practitioner"ã€‘
            ä¼æ¥­ã®CTOã€R&Dè²¬ä»»è€…ã€æ–°è¦äº‹æ¥­æ‹…å½“è€…ã€‚
            æŠ€è¡“ã®é€²åŒ–ãŒé€Ÿã™ãã¦æˆ¦ç•¥ãŒé™³è…åŒ–ã™ã‚‹ä¸å®‰ã‚’æŒã¤ãƒªãƒ¼ãƒ€ãƒ¼ãŸã¡ã€‚
            
            ã€ä¸»ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã€‘
            - Daily Briefing: å…¨ã‚»ã‚¯ã‚¿ãƒ¼ã‚’æ¨ªæ–­ã—ãŸæ—¥åˆŠæŠ€è¡“äºˆæ¸¬
            - Deep Dive: ç‰¹å®šæŠ€è¡“ï¼ˆå…¨å›ºä½“é›»æ± ã€AGIç­‰ï¼‰ã®å®Ÿç”¨åŒ–æ™‚æœŸäºˆæ¸¬
            - Roadmap: å‹•çš„ã«å¤‰åŒ–ã™ã‚‹æŠ€è¡“ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã®å¯è¦–åŒ–
            
            ## å«ã‚ã‚‹ã¹ãé …ç›®
            1. TechShiftã«ã¤ã„ã¦ï¼ˆã‚µã‚¤ãƒˆã®ç›®çš„ãƒ»ãƒ“ã‚¸ãƒ§ãƒ³ã€ŒDynamic Navigation Chartã€ï¼‰
            2. åŸºæœ¬æƒ…å ±ï¼ˆã‚µã‚¤ãƒˆåã€é‹å–¶è€…ã€è¨­ç«‹å¹´ã€ãŠå•ã„åˆã‚ã›å…ˆï¼‰ã‚’ãƒ†ãƒ¼ãƒ–ãƒ«å½¢å¼ã§
            3. ãƒŸãƒƒã‚·ãƒ§ãƒ³ãƒ»æä¾›ä¾¡å€¤ï¼ˆç‚¹ã§ã¯ãªãç·šã§è¦‹ã‚‹ã€ä¸€æ¬¡æƒ…å ±ã®å¾¹åº•ã€æ³¢åŠã®å¯è¦–åŒ–ï¼‰
            4. ä¸»ãªã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚«ãƒ†ã‚´ãƒªã®ç´¹ä»‹
            5. æƒ³å®šèª­è€…
            6. ãŠå•ã„åˆã‚ã›å…ˆ
            
            ## å‡ºåŠ›å½¢å¼
            - Markdownå½¢å¼ã§å‡ºåŠ›
            - è¦‹å‡ºã—ã¯H2ï¼ˆ##ï¼‰ã¨H3ï¼ˆ###ï¼‰ã‚’ä½¿ç”¨
            - åŸºæœ¬æƒ…å ±ã¯Markdownãƒ†ãƒ¼ãƒ–ãƒ«ã§æ•´ç†
            - å…ˆé€²çš„ã§ã€ä¿¡é ¼æ„ŸãŒã‚ã‚Šã€ãƒ“ã‚¸ãƒ§ãƒŠãƒªãƒ¼ãªæ–‡ç« 
            - æœªæ¥ã¸ã®æƒ…ç†±ãŒä¼ã‚ã‚‹å†…å®¹
            """),
            
            "contact": textwrap.dedent("""
            ã‚ãªãŸã¯ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆã®å°‚é–€å®¶ã§ã™ã€‚
            ä»¥ä¸‹ã®æƒ…å ±ã‚’åŸºã«ã€TechShiftã®ãŠå•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
            
            ã€ã‚µã‚¤ãƒˆæƒ…å ±ã€‘
            - ã‚µã‚¤ãƒˆå: TechShiftï¼ˆãƒ†ãƒƒã‚¯ã‚·ãƒ•ãƒˆï¼‰
            - é‹å–¶è€…: TechShiftç·¨é›†éƒ¨
            - ãŠå•ã„åˆã‚ã›: info@finshift.net
            - å¯¾å¿œæ™‚é–“: å¹³æ—¥ 10:00-18:00ï¼ˆåœŸæ—¥ç¥æ—¥ã‚’é™¤ãï¼‰
            
            ## å«ã‚ã‚‹ã¹ãé …ç›®
            1. ãŠå•ã„åˆã‚ã›ã«ã¤ã„ã¦ï¼ˆå°å…¥æ–‡ï¼‰
            2. ãŠå•ã„åˆã‚ã›æ–¹æ³•ï¼ˆãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼‰
            3. å¯¾å¿œæ™‚é–“
            4. ãŠå•ã„åˆã‚ã›å†…å®¹ã®ä¾‹ï¼ˆè¨˜äº‹ã®å†…å®¹ç¢ºèªã€ãƒ—ãƒ¬ã‚¹ãƒªãƒªãƒ¼ã‚¹é€ä»˜ã€å–æä¾é ¼ãªã©ï¼‰
            5. è¿”ä¿¡ã¾ã§ã®ç›®å®‰æ™‚é–“
            6. æ³¨æ„äº‹é …ï¼ˆå€‹äººæƒ…å ±ã®å–ã‚Šæ‰±ã„ãªã©ï¼‰
            
            ## å‡ºåŠ›å½¢å¼
            - Markdownå½¢å¼ã§å‡ºåŠ›
            - è¦‹å‡ºã—ã¯H2ï¼ˆ##ï¼‰ã¨H3ï¼ˆ###ï¼‰ã‚’ä½¿ç”¨
            - ç®‡æ¡æ›¸ãã‚’é©å®œä½¿ç”¨
            - ä¸å¯§ã§åˆ†ã‹ã‚Šã‚„ã™ã„æ–‡ç« 
            - ãŠå•ã„åˆã‚ã›ã—ã‚„ã™ã„é›°å›²æ°—
            
            ## æ³¨æ„ç‚¹
            - ãƒ¡ãƒ¼ãƒ«ã‚¢ãƒ‰ãƒ¬ã‚¹ã¯å¿…ãšè¨˜è¼‰
            - å¯¾å¿œæ™‚é–“ã‚’æ˜è¨˜
            - ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ãƒãƒªã‚·ãƒ¼ã¸ã®ãƒªãƒ³ã‚¯ã‚’æ¡ˆå†…
            """)
        }
        
        prompt = prompts.get(page_type)
        if not prompt:
            raise ValueError(f"Invalid page_type: {page_type}. Must be 'privacy', 'about', or 'contact'")
        
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model='gemini-3-pro-preview',
                contents=prompt
            )
            return response.text
        except Exception as e:
            print(f"Error generating static page: {e}")
            return None


    def generate_structured_summary(self, content):
        """
        Generate a structured JSON summary of the article for internal linking relevance.
        
        [USAGE ROLE]: Output Processing
        This method is used *AFTER* generation to extract metadata from the **INTERNAL** article.
        The result is saved in WordPress 'ai_structured_summary' field.
        """
        prompt = textwrap.dedent(f"""
        You are an expert content analyst. Analyze the following tech article and generate a structured summary in JSON format.
        This summary will be used by an AI system to identify relevant internal links.
        IMPORTANT: The content is Japanese, so the 'summary' and 'key_topics' MUST be written in Japanese.

        Article Content:
        {content[:4000]}... (truncated)

        Output JSON format (Strictly JSON only):
        {{
            "summary": "Detailed summary of the article content (300-500 chars) in Japanese. Focus on technical specifics and timeline impacts.",
            "key_topics": ["list", "of", "specific", "technologies", "covered", "(in Japanese)"],
            "entities": ["list", "of", "companies", "products", "or", "research_labs", "mentioned", "(preserve original names)"],
            "timeline_impact": "Brief description of how this affects the roadmap (Accelerated/Delay/Unchanged) in Japanese.",
            "technical_bottleneck": "Describe the technical bottleneck mentioned (if any) in Japanese."
        }}
        """)
        
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model='gemini-3-pro-preview',
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            import json
            return json.loads(response.text)
        except Exception as e:
            print(f"Structured summary generation failed: {e}")
            return None

    def generate_sns_content(self, title, content, article_type="market-analysis"):
        """
        Generate engaging SNS (Twitter/X) post content.
        Output is JSON: {"hook": "...", "summary": "...", "hashtags": ["#tag1", ...]}
        """
        # Truncate content for efficiency
        truncated_content = content[:3000]
        
        prompt = textwrap.dedent(f"""
        You are an expert social media manager for a futuristic tech media site "TechShift".
        Create an engaging X (Twitter) post content based on the following article.
        
        Target Audience: CTOs, R&D Leaders, Tech Investors (Visionary Practitioners).
        Goal: Maximize Engagement by appealing to "Deep Insight" and "Future Impact".
        
        Article Title: {title}
        Article Type: {article_type}
        Content (excerpt):
        {truncated_content}
        
        Requirements:
        1. **Hook**: A provocative opening. Focus on "What changed in the future timeline".
           - MUST include 1 relevant emoji (ï¿½, ğŸ§¬, ğŸ¤–, âš›ï¸, etc.).
           - Max 60 chars.
        2. **Summary**: Intellectual teaser. "Why this matters for the roadmap".
           - Focus on solving bottlenecks or new possibilities.
           - Max 120 chars.
        3. **Hashtags**: 5 hashtags optimized for Tech Communities.
           - **Required**:
             - Relevant Tech Keywords (e.g., #GenAI, #Quantum, #SolidStateBattery).
             - **Middle Words**: #æŠ€è¡“æˆ¦ç•¥, #æœªæ¥äºˆæ¸¬, #R_and_D (Avoid just #Technology).
             - Specific companies/labs if mentioned.
           - **Goal**: Reach professionals, not casual readers.
        
        4. Language: Japanese. 
        5. **Tone**: Visionary, Concise, Leading-edge. "Don't just read the news, read the future."
        
        Output JSON format (Strictly JSON only):
        {{
            "hook": "ğŸš€ GPT-5ã®æ¨è«–èƒ½åŠ›ãŒã€å‰µè–¬ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ã‚’ã€Œ2å¹´ã€çŸ­ç¸®ã™ã‚‹ã€‚",
            "summary": "å¾“æ¥ã®ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•ã¯éå»ã®ã‚‚ã®ã«ã€‚ãƒãƒ«ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ ãŒè§£æ±ºã—ãŸã€Œ3ã¤ã®ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ã€ã¨ã¯ï¼Ÿ",
            "hashtags": ["#GenerativeAI", "#DrugDiscovery", "#NVIDIA", "#BioTech", "#æŠ€è¡“æˆ¦ç•¥"]
        }}
        """)
        
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model='gemini-3-pro-preview',
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            import json
            return json.loads(response.text)
        except Exception as e:
            print(f"SNS content generation failed: {e}")
            # Fallback
            return {
                "hook": f"{title}",
                "summary": "æœ€æ–°ã®æŠ€è¡“å‹•å‘ã¨ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¸ã®å½±éŸ¿ã‚’åˆ†æã—ã¾ã—ãŸã€‚",
                "hashtags": ["#TechShift", "#DeepTech", "#FutureTrends", "#Innovation"]
            }

    def check_duplication(self, new_title, new_summary, existing_titles):
        """
        Check if a new article title semantically matches any existing titles.
        
        Args:
            new_title: The title of the potential new article
            new_summary: The summary of the potential new article
            existing_titles: List of existing article titles (WP posts + currently generated)
            
        Returns:
            The matching existing title if duplicate found, or None.
        """
        if not existing_titles:
            return None
            
        # Optimization: Don't check against massive lists if unnecessary.
        # But for now, we assume existing_titles is reasonably sized (e.g., < 50).
        
        prompt = f"""
        You are a duplicate content detector for a technology foresight media "TechShift".
        Determine if the "New Article" covers the **same specific news topic** as any of the "Existing Articles".
        
        Rule:
        - Return the EXACT title of the existing article ONLY if they are about the same specific news event or announcement.
        - If the new article is just a general topic match (e.g. both are about "Quantum Computing") but different specific news, return "None".
        - If the new article is a "Summary" or "Compilation" and the existing one is a single news, they are different -> return "None".
        - Different companies doing similar things are DIFFERENT -> return "None".
        - Same company doing the same thing (reported by different sources) are DUPLICATES -> return the existing title.
        
        New Article:
        Title: "{new_title}"
        Summary: "{new_summary}"
        
        Existing Articles:
        {json.dumps(existing_titles, ensure_ascii=False, indent=2)}
        
        Output JSON format:
        {{
            "is_duplicate": true/false,
            "duplicate_of": "Exact Title of Existing Article" (or null if false),
            "reason": "Brief explanation"
        }}
        """
        
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model='gemini-2.0-flash-exp',
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            result = json.loads(response.text)
            
            if result.get("is_duplicate"):
                print(f"Duplicate detected! '{new_title}' is duplicate of '{result.get('duplicate_of')}'")
                print(f"Reason: {result.get('reason')}")
                return result.get("duplicate_of")
            
            return None
            
        except Exception as e:
            print(f"Duplication check failed: {e}")
            return None

    # --- Daily Briefing Methods ---
    def check_relevance_batch(self, articles):
        """
        Check relevance for a batch of articles (list of dicts).
        Each dict must have 'url_hash', 'title', 'summary'.
        
        Returns: Dict mapping url_hash -> {'is_relevant': bool, 'reason': str}
        """
        if not articles:
            return {}
            
        # Prepare input list for prompt
        input_list = []
        for art in articles:
            input_list.append({
                "id": art.get('url_hash', 'unknown'),
                "title": art.get('title', ''),
                "summary": art.get('summary', '')[:500] 
            })
            
        prompt = f"""
        You are a "Deep Tech" news filter for TechShift.
        Analyze the following list of articles and determine if EACH one is relevant to **Engineering, R&D, Science, or Future Technology Analysis**.
        
        Criteria for "Relevant":
        - **Scientific Breakthroughs**: New discoveries in AI, Quantum, Bio, Energy, Space.
        - **Engineering Milestones**: Successful tests (e.g., Starship launch), pilot plant openings, efficiency records.
        - **Strategic Business**: M&A in deep tech, huge VC funding rounds, major government regulation on tech.
        
        Criteria for "Not Relevant" (Noise):
        - **Consumer Gadgets**: Smartwatch reviews, minor iPhone updates (unless revolutionary).
        - **General Politics**: Elections (unless directly affecting tech policy).
        - **Celebrity/Gossip**: Tech CEO scandals (unless affecting company roadmap).
        - **Short-term Stock Noise**: Daily price fluctuation without fundamental news.
        
        Input Articles:
        {json.dumps(input_list, ensure_ascii=False, indent=2)}
        
        Output JSON:
        A list of objects, one for each input article:
        [
            {{
                "id": "article_id_from_input",
                "is_relevant": true/false,
                "reason": "Brief explanation"
            }},
            ...
        ]
        """
        
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model='gemini-2.0-flash-exp', 
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            res_json = json.loads(response.text)
            
            # Map back to url_hash
            result_map = {}
            for res in res_json:
                u_hash = res.get('id')
                if u_hash:
                    result_map[u_hash] = {
                        'is_relevant': res.get('is_relevant', False),
                        'reason': res.get('reason', 'Unknown')
                    }
            return result_map
            
        except Exception as e:
            print(f"Batch relevance check failed: {e}")
            # Fallback: Mark all as Relevant with error note
            fallback_map = {}
            for art in articles:
                fallback_map[art.get('url_hash')] = {
                    'is_relevant': True,
                    'reason': f"Batch AI Check Failed: {e}"
                }
            return fallback_map

    def analyze_tech_impact(self, context_news_list, market_data_str, economic_events_str, region, extra_context=""):
        """
        Analyze tech news AND market data to generate "TechShift Insight" (The Shift, Catalyst, Next Wall).
        Returns: JSON with shift_analysis, hero_topic, etc.
        """
        news_text = "\n".join([f"- [{art['published_at']}] {art['title']}: {art['summary'][:200]}" for art in context_news_list])
        
        prompt = textwrap.dedent(f"""
        You are the "Shift Intelligence Engine" for TechShift. Analyze the provided data for the **{region}** region.
        
        ## Input Data
        
        ### 1. Macro Context
        - Market/Econ Data: {market_data_str}
        
        ### 2. Tech News (Last 24h)
        {news_text}
        
        ### 3. Context & Continuity
        {extra_context}

        **CRITICAL INSTRUCTION**:
        If "Today's Deep Dives" are provided in the Context above, you MUST prioritize them.
        - If a Deep Dive article matches the most significant shift, selecting it as the **Hero Topic** is highly recommended.
        - If it is important but secondary, it MUST be included in **Tech Radar**.
        - You must assume the reader wants to know about these specific deep dives.
        
        ## Analysis Tasks
        1. **Hero Topic**: Identify the single most overarching structural change (The "Lead Story").
        
        2. **Category Classification (Official Taxonomy)**:
           - Classify provided news into these 6 Sectors:
             - **Advanced AI** (LLM, Agent, Edge AI)
             - **Robotics & Mobility** (Humanoid, AV, Drone, Spatial Comp)
             - **Quantum & Tech** (Quantum, Semi, Materials)
             - **Green Tech** (Fusion, Battery, Climate)
             - **Life Science** (AI Drug Disc, Genome, MedTech)
             - **Space & Aero** (Rocket, Satellite, Moon)
           - *Note*: If no significant news exists for a sector, mark as "None".

        3. **Cross-Sector Impact (Synergy)**:
           - Analyze how updates in one sector affect another (e.g., "AI demand driving Energy breakthrough").

        4. **The Shift (Hero Analysis)**:
           - **The Shift**: "Rule X -> Rule Y".
           - **Catalyst**: "Why Now?".
           - **Next Wall**: "New Bottleneck".
           - **Signal**: "What to Watch".
        
        5. **AI Structured Summary**:
           - **summary**: Concise summary in **Japanese**.
           - **key_topics**: List of 3-5 tech keywords in **Japanese**.

        ## Output JSON
        {{
            "hero_topic": "...", 
            "shift_score": 85,
            "sector_updates": {{
                "AI & Robot": [ {{ "title": "...", "significance": "..." }} ],
                "Mobility & Space": [],
                "Quantum & Semi": [],
                "Climate & Energy": [],
                "Bio & Health": [],
                "Web3 & Economy": []
            }},
            "cross_sector_analysis": "...",
            "shift_analysis": {{
                "the_shift": "...",
                "catalyst": "...",
                "next_wall": "...",
                "signal": "..."
            }},
            "ai_structured_summary": {{
                "summary": "...",
                "key_topics": ["...", "..."]
            }},
            "reasoning": "..."
        }}
        """)
        
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model='gemini-3-pro-preview', # High reasoning model
                contents=prompt,
                config=types.GenerateContentConfig(
                    response_mime_type="application/json"
                )
            )
            result = json.loads(response.text)
            if isinstance(result, list):
                if len(result) > 0:
                    return result[0]
                else:
                    return {}
            return result
        except Exception as e:
            print(f"Tech Impact Analysis failed: {e}")
            return None

    def write_briefing(self, analysis_result, region, context_news=None, market_data_str=None, events_str=None, date_str=None, internal_links_context=None):
        """
        [Daily Briefing Pipeline]
        Write the final Daily Briefing article in Markdown based on the TechShift Standard.
        """
        # Prepare context strings
        news_text = ""
        if context_news:
             news_text = "\n".join([f"- {art['title']}" for art in context_news[:10]])

        prompt = textwrap.dedent(f"""
        You are the Editor-in-Chief of "TechShift". Write a "Daily Briefing" for the **{region}** region.
        
        ## Input Data
        
        ### 1. Shift Insight (Core Analysis)
        {json.dumps(analysis_result, ensure_ascii=False, indent=2)}
        
        ### 2. Macro Context (Raw Data)
        {market_data_str if market_data_str else "N/A"}
        
        ### 3. Key Tech News
        {news_text if news_text else "N/A"}
        
        ### 4. Internal Links (Reference)
        {internal_links_context if internal_links_context else "N/A"}
        
        ## Goal
        Create a **Navigation Chart** for the future. 
        Do NOT write a generic news summary. Write a strategic analysis of "Structural Changes".
        
        ## Tone & Style
        - **Insightful**: Connect the dots.
        - **Japanese Language**: Professional, crisp, and visionary.
        - **No Fluff**: Avoid "We hope", "Expected to". Use "The data suggests", "The barrier is".
        ## Output Structure (Japanese Headers)
        
        1. **Title**: Generated based on rules below.
        
        2. **ã€Today's Landscapeã€‘ (æœ¬æ—¥ã®é‡è¦ãƒã‚¤ãƒ³ãƒˆ)**
           - High-level summary of the day's tectonic shifts.
           - Bullet points of top 3 takeaways.

        3. **ã€Sector Updatesã€‘ (åˆ†é‡åˆ¥å‹•å‘)**
           - **Rule**: Only include sectors with significant updates (Torutsume).
           - **Mandatory**: If a "Deep Dive Article" exists for a sector (Context 4), you MUST introduce it here with a link.
           - Official Sectors:
             - **Advanced AI**
             - **Robotics & Mobility**
             - **Quantum & Tech**
             - **Green Tech**
             - **Life Science**
             - **Space & Aero**
        
        4. **ã€Cross-Sector Impactã€‘ (è¤‡åˆçš„å½±éŸ¿)**
           - Discuss how these shifts affect each other (Synergy).
           - e.g., "Quantum advancements accelerating Bio-simulation."

        5. **ã€Strategic Signalã€‘ (ä»Šå¾Œã®æ³¨ç›®ç‚¹)**
           - What to watch next week/month.
           - Specific KPIs or Events.

        6. **ã€Verdictã€‘ (çµè«–)**
           - Final thought on the overall market direction.
        
        ## Internal Linking
        - **MANDATORY**: Embed links to "Today's Featured Articles" naturally within the relevant Sector Update.
        - Format: `[Title](URL)`
        
        ## Title Rules (Pure SEO)
        1. **Goal**: Maximize Click-Through Rate (CTR) and Search Volume.
        2. **Format**: [Hero Keyword] + [Impact/Action]
        3. **Rules**:
           - **NO** "Daily Shift" or Date prefix.
           - Start with the most important Keyword (e.g., "å…¨å›ºä½“é›»æ± ", "GPT-5").
           - Include "Impact", "Roadmap", "Future", or "Industry Shift".
           - Limit to 32 characters (Google Search Snippet limit).
        4. **Good Examples**:
           - ã€Œå…¨å›ºä½“é›»æ± ã®é‡ç”£ã¯ã„ã¤ï¼Ÿæœ€æ–°ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—ã¨èª²é¡Œã€
           - ã€ŒAIã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒå¤‰ãˆã‚‹ä»•äº‹ã®æœªæ¥ã¨6ã¤ã®æ¥­ç•Œå‹•å‘ã€
           - ã€Œæ ¸èåˆç™ºé›»ã®ç¾çŠ¶ã¨2026å¹´ã®æ³¨ç›®ãƒã‚¤ãƒ³ãƒˆã€
        """)
        
        try:
            response = self._retry_request(
                self.client.models.generate_content,
                model='gemini-3-pro-preview',
                contents=prompt
            )
            return response.text
        except Exception as e:
            print(f"Briefing writing failed: {e}")
            return None

if __name__ == "__main__":
    # Test generation
    try:
        client = GeminiClient()
        print("GeminiClient initialized successfully.")
    except Exception as e:
        print(f"Initialization failed: {e}")
